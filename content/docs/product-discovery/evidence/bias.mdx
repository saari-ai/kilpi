---
title: Bias
description: Recognising and counteracting cognitive biases that distort discovery evidence
---

Bias is the most common reason discoveries produce incorrect conclusions. You can follow the entire methodology — frame problems, gather evidence, weight it carefully — and still reach the wrong answer if cognitive biases distort how you interpret what you find.

This page covers the biases most dangerous to discovery and the specific countermeasures for each.

## Confirmation bias

**What it is:** Seeking, interpreting, and remembering evidence that confirms your existing beliefs while ignoring or downweighting evidence that contradicts them.

**Why it is dangerous in discovery:** You started with hypotheses you believe are true. Every interview, every data point is filtered through that belief. You unconsciously ask questions that elicit confirming answers, highlight confirming quotes, and dismiss contradictory data as edge cases.

**Countermeasures:**

| Countermeasure | How to apply |
|----------------|-------------|
| Pre-register refutation criteria | Before gathering evidence, write down what would prove your hypothesis wrong. Commit to the criteria before you see the data. |
| Assign a devil's advocate | One team member's job is to actively look for disconfirming evidence and challenge the prevailing interpretation. |
| Blind evidence review | Have someone who does not know the hypothesis review the evidence and describe what patterns they see. |
| Count refuting evidence explicitly | In the Evidence Register, tag every item as supporting, refuting, or neutral. If you have zero refuting items, you are probably not looking hard enough. |

## Survivorship bias

**What it is:** Drawing conclusions only from people or companies who "survived" a selection process, ignoring those who did not.

**Why it is dangerous in discovery:** If you only interview current users, you miss everyone who tried and left, or who never started because the barrier was too high. Your evidence will skew toward people for whom the current situation is tolerable.

**Countermeasures:**

| Countermeasure | How to apply |
|----------------|-------------|
| Interview churned users | Actively recruit people who stopped using the product or abandoned the workflow you are studying. |
| Interview non-adopters | Talk to people in your target segment who are NOT doing the thing you expect. Why not? |
| Check the denominator | When citing statistics ("80% of users do X"), verify what population the percentage is based on. Does it include people who never started? |

## Selection bias

**What it is:** Your research sample is not representative of the population you are trying to understand.

**Why it is dangerous in discovery:** The easiest people to recruit are often the least representative — they are the most engaged, the most vocal, the most available. They have stronger opinions and more extreme experiences than the average user.

**Countermeasures:**

| Countermeasure | How to apply |
|----------------|-------------|
| Define screening criteria before recruiting | Write down who qualifies for the study and who does not, based on your target segment. Do not change criteria after seeing early results. |
| Recruit through multiple channels | Do not rely solely on your existing user base, your social media followers, or a single community. Each channel introduces its own bias. |
| Track who you talked to | Maintain a participant log with relevant demographics. Review it midway through research — are you skewed toward one sub-segment? |
| Include quiet users | Deliberately seek participants who are not power users, not community members, not early adopters. |

## Anchoring

**What it is:** Over-relying on the first piece of information you encounter. Early evidence disproportionately shapes your interpretation of all subsequent evidence.

**Why it is dangerous in discovery:** The first 2-3 interviews set a narrative. Every subsequent interview is interpreted through that initial frame. If the first interviewee has an extreme experience, it anchors your entire understanding.

**Countermeasures:**

| Countermeasure | How to apply |
|----------------|-------------|
| Delay synthesis | Do not form conclusions until you have at least 5 data points. Resist the urge to "see the pattern" after 2 interviews. |
| Randomise interview order | If interviewing across segments, mix the order rather than doing all of one segment first. |
| Re-read early evidence last | Before final synthesis, re-read your earliest evidence items. Do they still say what you thought they said? |

## Desirability bias

**What it is:** Participants tell you what they think you want to hear, or what makes them look competent.

**Why it is dangerous in discovery:** If participants sense you are building a product to solve a specific problem, they will confirm the problem exists to be helpful. They are not lying — they are being socially cooperative.

**Countermeasures:**

| Countermeasure | How to apply |
|----------------|-------------|
| Do not reveal hypotheses | Explain the general topic area but not what you believe. "We are researching how teams handle X" not "We think teams struggle with X." |
| Ask about past behaviour, not opinions | "Tell me about the last time..." produces more honest answers than "Do you think..." |
| Watch for agreement patterns | If every participant agrees with you, you are probably leading them. Vary your question framing. |
| Triangulate with observation | If people say they do X, observe whether they actually do X. The gap is informative. |

## Evidence review protocol

Run a formal bias check before moving any hypothesis to Supported or Refuted:

1. **Review the evidence register** for this hypothesis. Count supporting, refuting, and neutral items separately.
2. **Check for confirmation bias.** Is refuting evidence present? If not, did you look for it?
3. **Check for survivorship bias.** Does your sample include non-users and churned users?
4. **Check for selection bias.** Is your sample representative of the target segment?
5. **Check for anchoring.** Did early evidence disproportionately shape later interpretation?
6. **Check for desirability bias.** Were interviews conducted without revealing hypotheses?
7. **Document the assessment.** Note any bias risks and whether they were mitigated. This goes into the Discovery Brief.

If multiple bias risks are unmitigated, do not move the hypothesis to a terminal state. Either gather additional evidence to counteract the bias, or lower your confidence level in the Discovery Brief.
